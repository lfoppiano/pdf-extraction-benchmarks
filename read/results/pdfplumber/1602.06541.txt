1
A Survey of Semantic Segmentation II. TAXONOMYOFSEGMENTATIONALGORITHMS
Martin Thoma The computer vision community has published a
info@martin-thoma.de wide range of segmentation algorithms so far. Those
algorithms can be grouped by the kind of data they
operate on and the kind of segmentation they are able
Abstract—Thissurveygivesanoverviewoverdifferent
to produce.
techniques used for pixel-level semantic segmentation.
Metrics and datasets for the evaluation of segmenta- The following subsections will give four different
tion algorithms and traditional approaches for segmen- criteria by which segmentation algorithms can be
tation such as unsupervised methods, Decision Forests
classiﬁed.
and SVMs are described and pointers to the relevant
papers are given. Recently published approaches with This survey describes ﬁxed-class (see Section II-A),
convolutionalneuralnetworksarementionedandtypical single-class afﬁliation (see Section II-B) algorithms
6 problematic situations for segmentation algorithms are whichworkongrayscaleorcoloredsinglepixelimages
1 examined. A taxonomy of segmentation algorithms is (see Section II-C) in a completely automated, passive
0 given.
fashion (see Section II-D).
2
 
y
I. INTRODUCTION
a
M Semantic segmentation is the task of clustering A. Allowed classes
parts of images together which belong to the same
 
1 object class. This type of algorithm has several use- Semantic segmentation is a classiﬁcation task. As
1 cases such as detecting road signs [MBLAGJ+07], such, the classes on which the algorithm is trained is a
   detecting tumors [MBVLG02], detecting medical in- central design decision.
]
V strumentsinoperations[WAH97],coloncryptssegmen- Most algorithms work with a ﬁxed set of classes;
C tation [CRSS14], land use and land cover classiﬁca- some even only work on binary classes like fore-
. tion [HDT02]. In contrast, non-semantic segmentation ground vs background [RM07], [CS10] or street vs
cs onlyclusterspixelstogetherbasedongeneralcharacter- no street [BKTT15].
[ istics of single objects. Hence the task of non-semantic However, there are also unsupervised segmentation
 
  segmentation is not well-deﬁned, as many different algorithms which do not distinguish classes at all (see
2
v segmentations might be acceptable. Section V-B) as well as segmentation algorithms which
1 Several applications of segmentation in medicine are are able to recognize when they don’t know a class.
4 listed in [PXP00]. For example, in [GRC+08] a void class was added
5 Object detection, in comparison to semantic seg- for classes which were not in the training set. Such
6
mentation, has to distinguish different instances of the a void class was also used in the MSRCv2 dataset
0
. same object. While having a semantic segmentation (see Section III-B2) to make it possible to make more
2
is certainly a big advantage when trying to get object coarse segmentations and thus having to spend less
0
instances, there are a couple of problems: neighboring time annotating the image.
6
1 pixelsofthesameclassmightbelongtodifferentobject
: instances and regions which are not connected my
v
belong to the same object instance. For example, a
i B. Class afﬁliation of pixels
X
tree in front of a car which visually divides the car into
r two parts. Humans do an incredible job when looking at the
a
Thispaperisorganizedasfollows:Itbeginsbygiving world. For example, when we see a glass of water
a taxonomy of segmentation algorithms in Section II. standing on a table we can automatically say that there
A summary of quality measures and datasets which are istheglassandbehinditthetable,evenifweonlyhada
used for semantic segmentation follows in Section III. singleimageandwerenotallowedtomove.Thismeans
A summary of traditional segmentation algorithms and we simultaneously two labels to the coordinates of the
their characteristics follows in Section V, as well as a glass: Glass and table. Although there is much more
brief, non-exhaustive summary of recently published work being done on single class afﬁliation segmenta-
semantic segmentation algorithms which are based on tion algorithms, there is a publication about multiple
neural networks in Section VI. Finally, Section VII class afﬁliation segmentation [LRAL08]. Similarly,
informs the reader about typical problematic cases for recent publications in pixel-level object segmentation
segmentation algorithms. used layered models [YHRF12].
2
C. Input Data
The available data which can be used for the
inference of a segmentation varies by application.
• Grayscale vs colored: Grayscale images are
commonly used in medical imaging such as
magnetic resonance (MR) imaging or ultrasonog-
(a) ExampleScene (b) Visualizationofafoundseg-
raphy whereas colored photographs are obviously mentation
widespread.
Figure 1: An example of a scene and a possible visu-
• Excluding or including depth data: RGB-D,
sometimes also called range [HJBJ+96] is avail- alization of a found segmentation.
able in robotics, autonomous cars and recently
also in consumer electronics such as Microsoft
III. EVALUATIONANDDATASETS
Kinect [Zha12].
• Single image vs stereo images vs co- A. Quality measures for evaluation
segmentation: Single image segmentation is the
A performance measure is a crucial part of any
most wide-spread kind of segmentation, but using
machine learning system. As users of a semantic
stereoimageswasalreadytriedin[BVZ01].Itcan
segmentationsystemexpectcorrectresults,theaccuracy
be seen as a more natural way of segmentation as
is the most commonly used performance measure, but
most mammals have two eyes. It can also be seen
there are other measures of quality which matter when
as being related to having depth data.
segmentation algorithms are compared. This section
Co-segmentation as in [RMBK06], [CXGS12] is
gives an overview of those quality measures.
the problem of ﬁnding a consistent segmentation
1) Accuracy: Showingthecorrectnessofthesegmen-
for multiple images. This problem can be seen
tation hypotheses is done in most publications about
in two ways: One the one hand, it can be seen
semantic segmentation. However, there are a couple
as the problem of ﬁnding common objects in at
of different ways how this accuracy can be displayed.
least two images. On the other hand, every image
One way to give readers a ﬁrst qualitative impression
after the ﬁrst can be used as an additional source
of the obtained segmentations is by showing examples
of information to ﬁnd a meaningful segmentation.
such as Figure 1.
This idea can be extended to time series such as
However, this can only support the explanation of
videos.
particular problems or showcase special situation. For
• 2D vs 3D: Segmenting images is a 2D segmenta- meaningfulinformationabouttheoverallaccuracy,there
tion task where the smallest unit is called a pixel.
are a couple of metrics how accuracy can be deﬁned.
In 3D data, such as volumetric X-ray CT images For this section, let k ∈N be the number of classes,
as they were used in [HHR01], the smallest unit n ∈N with i,j ∈1,...,k be the number of pixels
ij 0
is called a voxel.
which belong to class i and were labeled as class j.
(n ) is called a confusion matrix. Let t =(cid:80)k n
ij i j=1 ij
be the total number of pixels of class i.
One way to compare segmentation algorithms is by
D. Operation state
the pixel-wise accuracy of the predicted segmentation
as done in many publications [SWRC06], [CP08],
The operation state of the classifying machine can
[LSD14]. This is also called per-pixel rate and de-
eitherbeactiveasin[SUM+11],[SSA12]whererobots ﬁned as (cid:80)ki=1nii. Taking the pixel-wise classiﬁcation
can move objects to ﬁnd a segmentation or passive, accuracy h(cid:80)akis=1twtio major drawbacks:
where the received image cannot be inﬂuenced. Among
the passive algorithms, some segment in a completely P1 Taskslikesegmentingimagesforautonomouscars
automaticfashion,othersworkinaninteractivemode. have large regions which have one class. This
One example would be a system where the user clicks makes achieving classiﬁcation accuracies of more
on the background or marks a coarse segmentation and than 30% with a priori knowledge only possible.
thealgorithmﬁndsaﬁne-grainedsegmentation.[BJ00], For example, a system might learn that a certain
[RKB04], [PS07] describe systems which work in an position of the image is most of the time “sky”
interactive mode. while another position is most of the time “road”.
3
P2 The manually labeled images could have a more segmentation,everyimageneedstobeprocessedwithin
coarse labeling. For example, a human classiﬁer 20ms [BKTT15]. This time is called latency.
could have labeled a region as “car” and the Most papers do not give exact values for the time
algorithm could have split that region into the theirapplicationneeds.Onereasonmightbethatthisis
general “car” and the more speciﬁc “wheel of a very hardware, implementation and in some cases even
car” data speciﬁc. For example, [HJBJ+96] notes that their
Three accuracy metrics which do not suffer from algorithm needs 10s on a Sun SparcStation 20. The
problem P1 are used in [LSD14]: fastestCPUeverproducedforthissystemhad200MHz.
• mean accuracy: k1 ·(cid:80)ki=1 ntiii ∈[0,1] CtaoinmedpaursiinnggtahnisIndtierleic7tl-y48w20itKhwreisthul3ts.9wGhHiczhwwoeurlednoobt-
• mean intersection over union:
1 ·(cid:80)k nii ∈[0,1] be meaningful.
k i=1 ti−nii+(cid:80)kj=1nji However, it does still make sense to mention the
• frequency weighted intersection over union:
execution time as well as the hardware in individual
((cid:80)ki=1ti)−1(cid:80)ki=1ti· ti−nii+n(cid:80)iikj=1nji ∈[0,1] papers.Thisgivestheinterestedreaderthepossibilityto
Another problem might be pixels which cannot be estimatehowdifﬁcultitmightbetoadjustthealgorithm
assigned to one of the known classes. For this reason, to work in the required time-constraints.
[SWRC06] makes use of a void class. This class gets Besides the latency, the throughput is another
completely ignored for all quality measures. Hence the relevant characteristic of algorithms and implementa-
totalnumberofpixelsisassumedtobewidth·height− tions for semantic segmentation. For example, for the
number of void pixels. automatic description of images in order to enable text
One way to deal with problem P1 and problem P2 search the throughput is of much higher importance
is giving the confusion matrix as done in [SWRC06]. than latency.
However, this approach is not feasible if many classes 3) Stability: A reasonable requirement on semantic
are given. segmentation algorithms is the stability of a segmen-
The F-measure is useful for binary classiﬁca- tation over slight changes in the input image. When
tion task such as the KITTI road segmentation the image data is sightly blurred by smoke such as
benchmark [FKG13] or crypt segmentation as done in Figure 4(c), the segmentation should not change.
by [CRSS14]. It is calculated as “the harmonic mean Also, two images which show a slight change in
of the precision and recall” [PH05]: perspective should also only result in slight changes in
the segmentation [PH05].
tp
Fβ =(1+β)2(1+β2)·tp+β2·fn+fp 4) Memory usage: Peak memory usage matters
when segmentation algorithms are used in devices like
where β = 1 is chosen in most cases and tp means smartphones or cameras, or when the algorithms have
true positive, fn means false negative and fp means to ﬁnish in a given time frame, run on the graphics
false positive. processing unit (GPU) and consume so much memory
Finally,itshouldbenotedthatalotofothermeasures for single image segmentation that only the latest
for the accuracy of segmentations were proposed for graphic cards can be used. However, no publication
non-semantic segmentation. One of those accuracy were available mentioning the peak memory usage.
measures is Normalized Probabilistic Rand (NPR)
index which was introduced in [UPH05] and eval-
B. Datasets
uated in [CSI+09] on dermoscopy images. Other
non-semantic segmentation measures were introduced The computer vision community produced a couple
in[MFTM01],butthereasonforcreatingthemseemsto of different datasets which are publicly available. In
betodealwiththeunder-deﬁnedtaskdescriptionofnon- the following, only the most widely used ones as well
semantic segmentation. These accuracy measures try to as three medical databases are described. An overview
dealwithdifferentlevelsofcoarsityofthesegmentation. over the quantity and the kind of data is given by
Thisismuchlessofaprobleminsemanticsegmentation Table I.
and thus those measures are not explained here. 1) PASCAL VOC: The PASCAL1 VOC2 challenge
2) Speed: Amaximumupperboundontheexecution was organized eight times with different datasets:
time for the inference on a single image is a hard Once every year from 2005 to 2012 [EVGW+b].
requirement for some applications. For example, in the
1patternanalysis,statisticalmodellingandcomputationallearning,
case of autonomous cars an algorithm which classiﬁes
anEUnetworkofexcellence
pixel as street or no-street and thus makes a semantic 2VisualObjectClasses
4
Beginning with 2007, a segmentation challenge was Training
added [EVGW+a]. Prediction
The dataset consists of annotated photographs from
Preprocessing
www.ﬂicker.com, a photo sharing website. There are Data
multiple challenges for PASCAL VOC. The 2012 Feature extraction augmentation
competition had ﬁve challenges of which one is a
segmentation challenge where a single class label was
givenforeachpixel.Theclassesare:aeroplane,bicycle,
Window Window-wise Post-
bird, boat, bottle, bus, car, cat, chair, cow, dining table, extraction Classiﬁcation processing
dog,horse,motorbike,person,pottedplant,sheep,sofa,
train, tv/monitor. Figure 2: A typical segmentation pipeline gets raw
Although no new competitions will be held, new pixel data, applies preprocessing techniques
algorithms can be evaluated on the 2010, 2011 and like scaling and feature extraction like HOG
2012 data via http://host.robots.ox.ac.uk:8080/ features. For training, data augmentation
The PASCAL VOC segmentation challenges use the techniques such as image rotation can be
segmentation over union criterion (see Section III-A). applied. For every single image, patches of
2) MSRCv2: Microsoft Research has published a the image called windows are extracted and
databaseof591photographswithpixel-levelannotation those windows are classiﬁed. The resulting
of 21 classes: aeroplane, bike, bird, boat, body, book, semantic segmentation can be reﬁned by
building, car, cat, chair, cow, dog, face, ﬂower, grass, simple morphologic operations or by more
road, sheep, sign, sky, tree, water. Additionally, there complexapproachessuchasMarkovRandom
is a void label for pixels which do not belong to Fields (MRFs).
any of the 21 classes or which are close to the
segmentationboundary.Thisallowsa“roughandquick
hand-segmentation which does not align exactly with
the object boundaries” [SWRC06]. IV. SEGMENTATIONPIPELINE
3) Medical Databases: The Warwick-QU Dataset
consists of 165 images with pixel-level annotation of
5 classes: “healthy, adenomatous, moderately differen- Typically, semantic segmentation is done with a
tiated, moderately-to-poorly differentiated, and poorly classiﬁer which operates on ﬁxed-size feature inputs
differentiated” [CSM09]. This dataset is part of the and a sliding-window approach [DT05], [YBCK10],
Gland Segmentation (GlaS) challenge. [SCZ08]. This means a classiﬁer is trained on images
The DIARETDB1 [KKV+14] is a dataset of 89 im- of a ﬁxed size. The trained classiﬁer is then fed with
ages fundus images. Those images show the interior rectangular regions of the image which are called win-
surfaceoftheeye.Fundusimagescanbeusedtodetect dows.Althoughtheclassiﬁergetsanimagepatchofe.g.
diabetic retinopathy. The images have four classes of 51px×51pxoftheenvironment,itmightonlyclassify
coarseannotations:hardandsoftexudates,hemorrhages the center pixel or a subset of the complete window.
and red small dots. This segmentation pipeline is visualized in Figure 2.
20 test and additionally 20 training retinal fun-
This approach was taken by [BKTT15] and a major-
dus images are available through the DRIVE data ity of the VOC2007 participants [EVGW+a]. As this
set [SAN+04]. The vessels were annotated. Addition-
approach has to apply the patch classiﬁer 512·512=
ally, [AP11] added vascular features.
262144timesforimagesofsize512px×512px,there
The Open-CAS Endoscopic Datasets [MHMK+14]
are techniques for speeding it up such as applying a
are 60 images taken from laparoscopic adrenalectomies
stride and interpolating the results.
and 60 images taken from laparoscopic pancreatic
Neuralnetworksareabletoapplytheslidingwindow
resections. Those are from 3 surgical procedures each.
approach in a very efﬁcient way by handling a trained
Half of the data was annotated by a medical expert for
network as a convolution and applying the convolution
“medial instrument” and “no medical instrument”. All
on the complete image.
images were labeled by anonymous untrained workers
to which they refer to as knowledge workers (KWs). However, there are alternatives. Namely MRFs and
One crowd annotation was obtained for each image by Conditional Random Fields (CRFs) which take the
a majority vote on a pixel basis of 10 segmentations information of the complete image and segment it in
given by 10 different KWs. an holistic approach.
5
V. TRADITIONALAPPROACHES thedirectionsiscalculatedforeachpatch.HOGfeatures
were proposed in [DT05] and are used in [BMBM10],
Image segmentation algorithms which use traditional
[FGMR10] for segmentation tasks.
approaches, hence don’t apply neural networks and
3) SIFT: Scale-invariant feature transform (SIFT)
make heavy use of domain knowledge, are wide-spread
feature descriptors describe keypoints in an image. The
in the computer vision community. Features which can
image patch of the size 16×16 around the keypoint
be used for segmentation are described in Section V-A,
is taken. This patch is divided in 16 distinct parts of
a very brief overview of unsupervised, non-semantic
the size 4×4. For each of those parts a histogram of
segmentationisgiveninSectionV-B,RandomDecision
8 orientations is calculated similar as for HOG features.
Forests are described in Section V-C, Markov Random
This results in a 128-dimensional feature vector for
Fields in Section V-E and Support Vector Machines
each keypoint.
(SVMs) in Section V-D. Postprocessing is covered in
ItshouldbeemphasizedthatSIFTisaglobalfeature
Section V-G.
for a complete image.
It should be noted that algorithms can use combina-
SIFT is described in detail in [Low04] and are used
tionof methods.For example, [TNL14]makesuse ofa
in [PTN09].
combinationofaSVMandaMRF.Also,auto-encoders
4) BOV: Bag-of-visual-words (BOV), also called
can be used to learn features which in turn can be used
bag of keypoints, is based on vector quantization.
by any classiﬁer.
Similar to HOG features, BOV features are histograms
which count the number of occurrences of certain
A. Features and Preprocessing methods
patternswithinapatchoftheimage.BOVaredescribed
Thechoiceoffeaturesisveryimportantintraditional in [CDF+04] and used in combination with SIFT
approaches. The most commonly used local and global feature descriptors in [CP08].
featuresareexplainedinthefollowingaswellasfeature 5) Poselets: Poselets rely on manually added extra
dimensionality reduction algorithms. keypoints such as “right shoulder”, “left shoulder”,
1) PixelColor: Pixelcolorindifferentimagespaces “right knee” and “left knee”. They were originally
(e.g. 3 features for RGB, 3 features for HSV, 1 feature used for human pose estimation. Finding those extra
forthegray-value)arethemostwidelyusedfeatures.A keypoints is easily possible for well-known image
typical image is in the RGB color space, but depending classes like humans. However, it is difﬁcult for classes
on the classiﬁer and the problem another color space like airplanes, ships, organs or cells where the human
mightresultinbettersegmentations.RGB,YcBcr,HSL, annotators do not know the keypoints. Additionally, the
Lab and YIQ are some examples used by [CRSS14]. keypointshavetobechosenforeverysingleclass.There
No single color space has been proven to be superior arestrategiestodealwiththoseproblemslikeviewpoint-
to all others in all contexts [CJSW01]. However, the dependentkeypoints.Poseletswereusedin[BMBM10]
most common choices seem to be RGB and HSI. to detect people and in [BBMM11] for general object
ReasonsforchoosingRGBissimplicityandthesupport detection of the PASCAL VOC dataset.
by programming languages, whereas the choice of 6) Textons: A texton is the minimal building block
the HSI color space might make it simpler for the ofvision.Thecomputervisionliteraturedoesnotgivea
classiﬁer to become invariant to illumination. One strict deﬁnition for textons, but edge detectors could be
reason for choosing CIE-L*a*b* color space is that it one example. One might argue that deep learning tech-
approximates human perception of brightness [KP92]. niques with Convolution Neuronal Networks (CNNs)
It follows that choosing the L*a*b color space helps learn textons in the ﬁrst ﬁlters.
algorithms to detect structures which are seen by An excellent explanation of textons can be found
humans.Anotherwayofimprovingthestructurewithin in [ZGWX05].
an image is histogram equalization, which can be 7) Dimensionality Reduction: High-resolution im-
applied to improve contrast [PAA+87], [RM07]. ageshavealotofpixels.Havingoneormorefeatureper
2) Histogram of oriented Gradients: Histogram of pixelresultsinwelloveramillionfeatures.Thismakes
oriented gradients (HOG) features interpret the image training difﬁcult while the higher resolution might not
as a discrete function I : N2 → {0,...,255} which contain much more information. A simple approach
mapstheposition(x,y)toacolor.Foreachpixel,there to deal with this is downsampling the high-resolution
are two gradients: The partial derivative of x and y. image to a low-resolution variant. Another way of
Now the original image is transformed to two feature doing dimensionality reduction is principal component
mapsofequalsizewhichrepresentsthegradient.These analysis (PCA), which is applied by [COWR11]. The
featuremapsaresplittedintopatchesandahistogramof idea behind PCA is to ﬁnd a hyperplane on which all
6
feature vectors can be projected with a minimal loss The 4-neighborhood (north, east, south west) or an 8-
of information. A detailed description of PCA is given neighborhood (north, north-east, east, south-east, south,
by [Smi02]. south-west, west, north-west) are plausible choices.
One problem of PCA is the fact that it does not One way to cut the edges is by building a minimum
distinguish different classes. This means it can happen spanning tree and removing edges above a threshold.
that a perfectly linearly separable set of feature vectors This threshold can either be constant, adapted to the
becomes not separable at all after applying PCA. graph or adjusted by the user. After the edge-cutting
There are many other techniques for dimensionality step, the connected components are the segments.
reduction. An overview and a comparison over some A graph-based method which ranked 2nd in the
of them is given by [vdMPvdH09]. Pascal VOC 2010 challenge [EVGW+10] is described
in [CS10]. The system makes heavy use of the multi-
cue contour detector globalPb [MAFM08] and needs
B. Unsupervised Segmentation about 10GB of main memory [CS11].
Unsupervised segmentation algorithms can be used 3) Random Walks: Random walks belong to the
in supervised segmentation as another source of infor- graph-based image segmentation algorithms. Random
mation or to reﬁne a segmentation. While unsupervised walk image segmentation usually works as follows:
segmentationalgorithmscanneverbesemantic,theyare Seed points are placed on the image for the different
well-studied and deserve at least a very brief overview. objects in the image. From every single pixel, the
Semantic segmentation algorithms store information probability to reach the different seed points by a
about the classes they were trained to segment while random walk is calculated. This is done by taking
non-semantic segmentation algorithms try to detect image gradients as described in Section V-A for HOG
consistent regions or region boundaries. features. The class of the pixel is the class of which a
1) Clustering Algorithms: Clustering algorithms can seed point will be reached with highest probability. At
directly be applied on the pixels, when one gives a ﬁrst, this is an interactive segmentation method, but it
feature vector per pixel. Two clustering algorithms are can be extended to be non-interactive by using another
k-means and the mean-shift algorithm. segmentation methods output as seed points.
The k-means algorithm is a general-purpose cluster- 4) Active Contour Models: Active contour models
ing algorithm which requires the number of clusters to (ACMs) are algorithms which segment images roughly
be given beforehand. Initially, it places the k centroids along edges, but also try to ﬁnd a border which is
randomly in the feature space. Then it assigns each smooth. This is done by deﬁning a so called energy
data point to the nearest centroid, moves the centroid function which will be minimized. They were initially
to the center of the cluster and continues the process described in [KWT88]. ACMs can be used to segment
until a stopping criterion is reached. A faster variant is an image or to reﬁne segmentation as it was done
described in [Har75]. in [AM98] for brain MR images.
k-means was applied by [CLP98] for medical image 5) Watershed Segmentation: The watershed algo-
segmentation. rithm takes a grayscale image and interprets it as a
Another clustering algorithm is the mean-shift algo- height map. Low values are catchment basins and
rithm which was introduced by [CM02] for segmen- the higher values between two neighboring catchment
tation tasks. The algorithm ﬁnds the cluster centers basins is the watershed. The catchment basins should
by initializing centroids at random seed points and contain what the developer wants to capture. This
iteratively shifting them to the mean coordinate within implies that those areas must be dark on grayscale
acertainrange.Insteadoftakingahardrangeconstraint, images. The algorithm starts to ﬁll the basins from
the mean can also be calculated by using any kernel. the lowest point. When two basins are connected, a
This effectively applies a weight to the coordinates watershed is found. The algorithm stops when the
of the points. The mean shift algorithm ﬁnds cluster highest point is reached.
centers at positions with a highest local density of A detaileddescription ofthe watershed segmentation
points. algorithm is given in [RM00].
2) Graph Based Image Segmentation: Graph-based The watershed segmentation was used in [JLD03] to
imagesegmentationalgorithmstypicallyinterpretpixels segment white blood cells. As the authors describe,
as vertices and an edge weight is a measure of the segmentation by watershed transform has two
dissimilarity such as the difference in color [FH04], ﬂaws:Over-segmentationduetolocalminimaandthick
[Fel]. There are several different candidates for edges. watersheds due to plateaus.
7
C. Random Decision Forests 1) If data is linearly separable, it can be separated
by a hyperplane. There is one hyperplane which
Random Decision Forests were ﬁrst proposed
maximizes the distance to the next datapoints
in [Ho95]. This type of classiﬁer applies techniques
called ensemble learning, where multiple classiﬁers (supportvectors).Thishyperplaneshouldbetaken:
are trained and a combination of their hypotheses is
1
used. One ensemble learning technique is the random minimize (cid:107)w(cid:107)2
subspaces method where each classiﬁer is trained w,b 2
s.t. ∀m y ·((cid:104)w,x (cid:105)+b)≥1
on a random subspace of the feature space. Another i=1 i i
(cid:124) (cid:123)(cid:122) (cid:125)
ensemble learning technique is bagging, which is sgn appliedtothisgivestheclassiﬁcation
training the trees on random subsets of the training set.
2) Eveniftheunderlyingprocesswhichgeneratesthe
In the case of Random Decision Forests, the classiﬁers
features for the two classes is linearly separable,
are decision trees. A decision tree is a tree where each
noise can make the data not separable. The intro-
innernodeusesoneormorefeaturestodecideinwhich
duction ofslackvariables to relaxthe requirement
branch to descend. Each leaf is a class.
of linear separability solves this problem. The
One strength of Random Decision Forests compared
trade-off between accepting some errors and a
tomanyotherclassiﬁerslikeSVMsandneuralnetworks
more complex model is weighted by a parameter
is that the scale of measure of the features (nominal,
C ∈ R+. The bigger C, the more errors are
ordinal, interval, ratio) can be arbitrary. Another advan- 0
accepted. The new optimization problem is:
tage of Random Decision Forests compared to SVMs,
for example, is the speed of training and classiﬁcation. 1 (cid:88)m
Decision trees were extensively studied in the past minwimize2(cid:107)w(cid:107)2+C· ξi
20 years and a multitude of training algorithms have i=1
been proposed (e.g. ID3 in [Qui86], C4.5 in [Qui93]). s.t. ∀mi=1yi·((cid:104)w,xi(cid:105)+b)≥1−ξi
Possible training hyperparameters are the measure to
Note that 0 ≤ ξ ≤ 1 means that the data point
i
evaluatethe“goodnessofsplit”[Min89],thenumberof
is within the margin, whereas ξ ≥1 means it is
i
decision trees being used, and if the depth of the trees
misclassiﬁed. An SVM with C >0 is also called
is restricted. Typically in the context of classiﬁcation,
a soft-margin SVM.
decision trees are trained by adding new nodes until
3) The primal problem is to ﬁnd the normal vector
eachleafcontainsonlynodesofasingleclassoruntilit
w and the bias b. The dual problem is to express
is not possible to split further. This is called a stopping
w as a linear combination of the training data x :
i
criterion.
There are two typical training modes: Central axis (cid:88)m
w= α y x
projection and perceptron training. In training, for i i i
each node a hyperplane is searched which is optimal i=1
according to an error function. where y ∈ {−1,1} represents the class of the
i
Random Decision Forests with texton features (see training example and α are Lagrange multipliers.
i
Section V-A6) are applied in [SJC08] for segmentation. The usage of Lagrange multipliers is explained
In the [MSC] dataset, they report a per-pixel accuracy with some examples in [Smi04]. The usage of the
rate of 66.9% for their best system. This system Lagrange multipliers α changes the optimization
i
requires415msforthesegmentationof320px×213px problem depend on the α which are weights for
i
images on a single 2.7GHz core. On the Pascal the feature vectors. It turns out that most α will
i
VOC 2007 dataset, they report an average per-pixel be zero. The non-zero weighted vectors are called
accuracy for their best segmentation system of 42%. support vectors.
An excellent introduction to Random Decision The optimization problem is now, according
Forestsforsemanticsegmentationisgivenby[SCZ08]. to [Bur98]:
m m m
(cid:88) 1(cid:88)(cid:88)
D. SVMs maximize α − α α y y (cid:104)x ,x (cid:105)
SVMs are well-studied binary classiﬁers which can αi i=1 i 2 i=1j=1 i j i j i j
be described by ﬁve central ideas. For those ideas, the s.t. ∀m 0≤α ≤C
i=1 i
training data is represented as (xi,yi) where xi is the (cid:88)m
feature vector and yi ∈ {−1,1} the binary label for s.t. αiyi =0
training example i∈{1,...,m}. i=1
8
4) Not every dataset is linearly separable. This prob- yy77 yy88 yy99
lem is approached by transforming the feature
xx xx xx
77 88 99
vectors x with a non-linear mapping Φ into yy44 yy55 yy66
a higher dimensional (probably ∞-dimensional)
xx xx xx
44 55 66
space. As the feature vectors x are only used yy11 yy22 yy33
within scalar product (cid:104)x ,x (cid:105), it is not necessary
i j xx xx xx
11 22 33
to do the transformation. It is enough to do the
calculation Figure 3: CRF with 4-neighborhood. Each node xi
representsapixelandeachnodey represents
i
K(x ,x )=(cid:104)x ,x (cid:105)
i j i j a label.
This function K is called a kernel. The idea of
never explicitly transforming the vectors x to the
i
getslabeledasshowninFigure3.Forexample,aMRF
higher dimensional space is called the kernel trick.
whichistrainedonimagesofthesize224px×224pixel
Common kernels include the polynomial kernel
and gets the raw RGB values as features has
K (x ,x )=((cid:104)x ,x (cid:105)+r)p
P i j i j
224·224·3+224·224=200704
of degree p and coefﬁcient r, the Gaussian radial (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
input output
basis function (RBF) kernel
random variables. Those random variables are condi-
KGauss(xi,xj)=e−γ(cid:107)x2iσ−2xj(cid:107)2 tionally independent, given their local neighborhood.
These (in)dependencies can be expressed with a graph.
and the sigmoid kernel Let G=(V,E) be the associated undirected graph
of an MRF and C be the set of all maximal cliques in
K (x ,x )=tanh(γ(cid:104)x ,x (cid:105)−r)
tanh i j i j
that graph. Nodes represent random variables x,y and
where the parameter γ determines how much edges represent conditional dependencies. Just like in
inﬂuence single training examples have. he 4-neighborhood [SWRC06] and the 8-neighborhood
5) ThedescribedSVMscanonlydistinguishbetween are reasonable choices for constructing the graph.
two classes. Common strategies to expand those Typically,randomvariablesyrepresenttheclassofa
binary classiﬁers to multi-class classiﬁcation is singlepixel,randomvariablesxrepresentapixelvalues
the one-vs-all and the one-vs-one strategy. In the and edges represent pixel neighborhood in computer
one-vs-all strategy n classiﬁers have to be trained vision problems segmentation problems where MRFs
which can distinguish one of the n classes against are used. Accordingly, the random variables y live
all other classes. In the one-vs-one strategy n2−n on 1,...,nr of classes and the random variables x
2
classiﬁers are trained; one classiﬁer for each pair typically live on 0,...,255 or [0,1].
of classes. The probability of x,y can be expressed as
A detailed description of SVMs can be found
1
in [Bur98]. P(x,y)= e−E(x,y)
Z
SVMs are used by [YHRF12] on the 2009 and 2010
PASCAL segmentation challenge [EVGW+10]. They where Z = (cid:80) e−E(x,y) is a normalization term
x,y
did not hand their classiﬁer in to the challenge itself, called the partition function and E is called the energy
but calculated an average rank of 7 among the different function. A common choice for the energy function is
categories. (cid:88)
E(x,y)= ψ (x,y)
[FGMR10] also used an SVM based method with c
HOG features and achieved the 7th rank in the 2010 c∈C
PASCAL segmentation challenge by mean accuracy. It where ψ is called a clique potential. One choice for
needs about 2s on a 2.8GHz 8-core Intel processor. cliques of size two x,y=(x ,x ) is [KP06]
1 2
(cid:40)
+w if x (cid:54)=x
E. Markov Random Fields ψ (x ,x )=wδ(x ,x )= 1 2
c 1 2 1 2
−w if x =x
1 2
MRFs are undirected probabilistic graphical models
which are wide-spread model in computer vision. The According to [Mur12], the most common way of
overall idea of MRFs is to assign a random variable for inference over the posterior MRF in computer vision
eachfeatureandarandomvariableforeachpixelwhich problems is Maximum A Posteriori (MAP) estimation.
9
Detailed introductions to MRFs are given by VI. NEURALNETWORKSFORSEMANTIC
[BKR11], [Mur12]. MRFs are used by [ZBS01] and SEGMENTATION
[MSB12] for image segmentation. Artiﬁcial neural networks are classiﬁers which are
inspired by biologic neurons. Every single artiﬁcial
F. Conditional Random Fields neuron has some inputs which are weighted and sumed
up. Then, the neuron applies a so called activation
CRFs are MRFs where all clique potentials are
functiontotheweightedsumandgivesanoutput.Those
conditioned on input features [Mur12]. This means,
neurons can take either a feature vector as input or the
instead of learning the distribution P(y,x), the task
output of other neurons. In this way, they build up
is reformulated to learn the distribution P(y|x). One
feature hierarchies.
consequence of this reformulation is that CRFs need
The parameters they learn are the weights w ∈ R.
much less parameters as the distribution of x does
Theyarelearnedbygradientdescent.Todoso,anerror
not have to be estimated. Another advantage of CRFs
function—usuallycross-entropyormeansquarederror
compared to MRFs is that no distribution assumption
— is necessary. For the gradient descent algorithm, one
about x has to be made.
sees the labeled training data as given, the weights
A CRF has the partition function Z:
as variables and the error function as a surface in
(cid:88)
Z(x)= P(x,y) this weight-space. Minimizing the error function in the
y weight space adapts the neural network to the problem.
There are lots of ideas around neural networks like
and joint probability distribution
regularization, better optimization algorithms, automat-
1 (cid:89) ically building up architectures, design choices for
P(y|x)= ψ (y |x)
Z(x) c c activationfunctions.Thisisnotexplainedindetailhere,
c∈C
but some of the mayor breakthroughs are outlined.
The simplest way to deﬁne the clique potentials ψ is CNNs are neural networks which learn image ﬁlters.
the count of the class yc given x added with a positive Theydrasticallyreducethenumberofparameterswhich
smoothing constant to prevent the complete term from have to be learned while being still general enough for
getting zero. theproblemdomainofimages.ThiswasshownbyAlex
CRFs as described in [LRKT09] have reached top Krizhevsky et al. in [KSH12]. One major idea was a
performance in PASCAL VOC 2010 [VOC10] and clever regularization called dropout training, which set
are also used in [HZCP04], [SWRC06] for semantic the output of neurons while training randomly to zero.
segmentation. Another contribution was the usage of an activation
A method similar to CRFs was proposed function called rectiﬁed linear unit:
in [GBVdW+10]. The system of Gonfaus et.al.
ranked 1st by mean accuracy in the segmentation task ϕReLU(x)=max(0,x)
of the PASCAL VOC 2010 challenge [EVGW+10]. Those are much faster to train than the commonly used
An introduction to CRFs is given by [SM11]. sigmoid activation functions
1
ϕ (x)=
G. Post-processing methods Sigmoid e−x+1
Post-processing reﬁne a found segmentation and Krizhevsky et al. implemented those ideas and partici-
remove obvious errors. For example, the morphological pated in the ImageNet Large-Scale Visual Recognition
operations opening and closing can remove noise. The Challenge (ILSVRC). The best other system, which
opening operation is a dilation followed by a erosion. used SIFT features and Fisher Vectors, had a perfor-
This removes tiny segments. The closing operation is a mance of about 25.7% while the network by Alex
erosion followed by a dilation. This removes tiny gaps Krizhevsky et al. got 17.0% error rate on the ILSVRC-
in otherwise ﬁlled regions. They were used in [CLP98] 2010 dataset. As a preprocessing step, they downsam-
for biomedical image segmentation. pledallimagestoaﬁxedsizeof256px×256pxbefore
Anotherwayofreﬁnementofthefoundsegmentation they fed the features into their network. This network
is by adjusting the segmentation to match close edges. is commonly known as AlexNet.
This was used in [BBMM11] with an ultra-metric Since AlexNet was developed, a lot of different
contour map [AMFM09]. neural networks have been proposed. One interesting
Active contour models are another example of a exampleis[PC13],wherearecurrentCNNforsemantic
post-processing method [KWT88]. segmentation is presented.
10
Another notable paper is [LSD14]. The algorithm
presentedtheremakesuseofaclassifyingnetworksuch
as AlexNet, but applies the complete network as an
image ﬁlter. This way, each pixel gets a probability
distribution for each of the trained classes. By taking
the most likely class, a semantic segmentation can be
done with arbitrary image sizes.
A very recent publication by Dai et al. [DHS15] (a) LensFlare (b) Vignetting
showed that segmentation with much deeper networks Imageby[Hus07] Imageby[Man12]
is possible and achieves better results.
More detailed explanations to neural networks for
visual recognition is given by [LKJ15].
VII. POSSIBLEPROBLEMSINTHEDATAFOR
SEGMENTATIONALGORITHMS
Different segmentation workﬂows have different
problems. However, there are a couple of special cases (c) Smokebycauterization (d) Camouﬂage
Imageby[GVSY13] Imageby[Kaf07]
which should be tested. Those cases might not occur
often in the training data, but it could still happen in
the productive system.
I am not aware of any systematic work which exam-
ined the inﬂuence of problems such as the following.
A. Lens Flare
Lens ﬂare is the effect of light getting scattered in (e) Transparency (f) Viewpoint
the lens system of the camera. The testing data set of
the KITTI road evaluation benchmark [FKG13] has a Figure 4: Examples of images which might cause
couple of photos with this problem. Figure 4(a) shows semantic segmentation systems to fail.
an extreme example of lens ﬂare.
B. Vignetting 2) Camouﬂage: Some objects, like animals in the
wild,activelytrytohide(seeFigure4(d)asanexample).
Vignettingistheeffectofaphotographgettingdarker
In other cases it might just be bad luck that objects
inthecorners.Thiscanhavemanyreasons,forexample
are hard for humans to detect. This problem has two
ﬁlters on the camera blocking light at the corners.
interesting aspects: On the one hand, the segmenting
systemmightsufferfromthesameproblemsashumans
C. Blurred images
do. On the other hand, the segmenting system might be
Images can be blurred for a couple of reasons. A better than humans are, but it is forced to learn from
problem with the lenses mechanics, focusing on the images labeled by humans. If the labels are wrong, the
wrongpoint,tooquickmovement,smokeorfoam.One system is forced to learn something wrong.
example of a blurred image is Figure 4(c), which was
3) Semi-transparent Occlusion: Some objects like
takenduringaninvivoporcineprocedureofdiaphragm
drinkingglassescanbevisibleandstillleavetheobject
dissection. The smoke was caused by cauterization.
behind them visible as shown in Figure 4(e). This is
mainly a deﬁnition problem: Is the seen pixel the glass
D. Other Problems label or the smartphone label?
If the following effects can occur at all and if they 4) Viewpoints: Changes in viewpoints can be a
are problems depends heavily on the problem domain problem, if they don’t occur in the training data. For
and the used model. example,animagecaptioningsystemwhichwastrained
1) Partial Occlusions: Segmentation systems which on photographs of professional photographers might
employ a model of the objects which should be not have photos from the point of view of a child. This
segmented might suffer from partial occlusions. is visualized in Figure 4(f).
11
VIII. DISCUSSION REFERENCES
Ohta et al. wrote [OKS78] 38 years ago. It is one [AM98] M. S. Atkins and B. T. Mackiewich, “Fully
of the ﬁrst papers mentioning semantic segmentation. automatic segmentation of the brain in
mri,” Medical Imaging, IEEE Transactions
In this time, a lot of work was done and many
on, vol. 17, no. 1, pp. 98–107, Feb. 1998.
different directions have been explored. Different kinds [Online].Available:http://ieeexplore.ieee.org/xpls/
of semantic segmentation have emerged. abs_all.jsp?arnumber=668699
[AMFM09] P. Arbelaez, M. Maire, C. Fowlkes, and
This paper presents a taxonomy of those kinds
J. Malik, “From contours to regions: An
of semantic segmentation and a brief overview of empirical evaluation,” in Computer Vision and
completely automatic, passive, semantic segmentation Pattern Recognition, 2009. CVPR 2009. IEEE
Conferenceon. IEEE,Jun.2009,pp.2294–2301.
algorithms.
[Online].Available:http://ieeexplore.ieee.org/xpls/
Future work includes a comparative study of abs_all.jsp?arnumber=5206707
those algorithms on publicly available dataset such [AP11] G. Azzopardi and N. Petkov, “Detection of
retinal vascular bifurcations by trainable v4-like
as the ones presented in Table I. Another open
ﬁlters,” in Computer Analysis of Images and
question is the inﬂuence of the problems described Patterns. Springer,2011,pp.451–459.[Online].
inSectionVII.Thiscouldbedoneusingasubsetofthe Available:http://www.cs.rug.nl/~imaging/databases/
retina_database/retinalfeatures_database.html
thousands of images of Wikipedia Commons, such as
[BBMM11] T. Brox, L. Bourdev, S. Maji, and J. Malik,
https://commons.wikimedia.org/wiki/Category:Blurring
“Object segmentation by alignment of poselet
for blurred images. activationstoimagecontours,”inComputerVision
and Pattern Recognition (CVPR), 2011 IEEE
A combination of different classiﬁers in an ensemble
Conferenceon. IEEE,Jun.2011,pp.2225–2232.
would be an interesting option to explore in order to [Online].Available:http://ieeexplore.ieee.org/xpls/
improve accuracy. Another direction which is currently abs_all.jsp?arnumber=5995659
studiediscombiningclassiﬁerssuchasneuralnetworks [BJ00] Y. Boykov and M.-P. Jolly, “Interactive organ
segmentationusinggraphcuts,”inMedicalImage
with CRFs [ZJRP+15].
Computing and Computer-Assisted Intervention–
MICCAI 2000. Springer, 2000, pp. 276–
286.[Online].Available:http://link.springer.com/
chapter/10.1007/978-3-540-40899-4_28
[BKR11] A.Blake,P.Kohli,andC.Rother,Markovrandom
ﬁeldsforvisionandimageprocessing. MitPress,
2011.
[BKTT15] S.Bittel,V.Kaiser,M.Teichmann,andM.Thoma,
“Pixel-wise segmentation of street with neural
networks,”arXivpreprintarXiv:1511.00513,2015.
[Online].Available:http://arxiv.org/abs/1511.00513
[BMBM10] L. Bourdev, S. Maji, T. Brox, and J. Malik,
“Detecting people using mutually consistent
poselet activations,” in Computer Vision–ECCV
2010. Springer, 2010, pp. 168–181. [Online].
Available:http://link.springer.com/chapter/10.1007/
978-3-642-15567-3_13#page-1
[Bur98] C.J.Burges,“Atutorialonsupportvectormachines
forpatternrecognition,”Dataminingandknowledge
discovery,vol.2,no.2,pp.121–167,1998.
[BVZ01] Y. Boykov, O. Veksler, and R. Zabih, “Fast
approximateenergyminimizationviagraphcuts,”
Pattern Analysis and Machine Intelligence, IEEE
Transactions on, vol. 23, no. 11, pp. 1222–1239,
2001.[Online].Available:http://ieeexplore.ieee.org/
xpls/abs_all.jsp?arnumber=969114
[CDF+04] G. Csurka, C. Dance, L. Fan, J. Willamowski,
and C. Bray, “Visual categorization with bags of
keypoints,”inWorkshoponstatisticallearningin
computervision,ECCV,vol.1,no.1-22. Prague,
2004,pp.1–2.
[CJSW01] H.-D. Cheng, X. Jiang, Y. Sun, and J. Wang,
“Colorimagesegmentation:advancesandprospects,”
Patternrecognition,vol.34,no.12,pp.2259–2281,
2001.
[CLP98] C. W. Chen, J. Luo, and K. J. Parker, “Image
segmentation via adaptive k-mean clustering and
knowledge-based morphological operations with
biomedicalapplications,”ImageProcessing,IEEE
Transactionson,vol.7,no.12,pp.1673–1683,Dec.
12
1998.[Online].Available:http://ieeexplore.ieee.org/ vol. 1, June 2005, pp. 886–893 vol. 1.
xpls/abs_all.jsp?arnumber=730379 [Online].Available:http://ieeexplore.ieee.org/xpls/
[CM02] D. Comaniciu and P. Meer, “Mean shift: A abs_all.jsp?arnumber=1467360
robust approach toward feature space analysis,” [EVGW+a] M. Everingham, L. Van Gool, C. K. I.
Pattern Analysis and Machine Intelligence, IEEE Williams, J. Winn, and A. Zisserman, “The
Transactionson,vol.24,no.5,pp.603–619,2002. PASCAL Visual Object Classes Challenge
[Online]. Available: http://ieeexplore.ieee.org/xpl/ 2007 (VOC2007) Results,” http://www.pascal-
login.jsp?tp=&arnumber=1000236 network.org/challenges/VOC/voc2007/workshop/index.html.
[COWR11] C. Chen, J. Ozolek, W. Wang, and G. K. Rohde, [Online]. Available: http://host.robots.ox.ac.uk:
“A pixel classiﬁcation system for segmenting 8080/pascal/VOC/voc2007/index.html
biomedicalimagesusingintensityneighborhoods [EVGW+b] ——,“ThePASCALVisualObjectClassesChal-
anddimensionreduction,”inBiomedicalImaging: lenge2012(VOC2012)Results,”http://www.pascal-
From Nano to Macro, 2011 IEEE International network.org/challenges/VOC/voc2012/workshop/index.html.
Symposium on. IEEE, 2011, pp. 1649–1652. [Online]. Available: http://host.robots.ox.ac.uk:
[Online].Available:https://www.andrew.cmu.edu/ 8080/pascal/VOC/voc2012/index.html
user/gustavor/chen_isbi_11.pdf [EVGW+10] M. Everingham, L. Van Gool, C. K. Williams,
[CP08] G. Csurka and F. Perronnin, “A simple high J.Winn,andA.Zisserman,“Thepascalvisualobject
performanceapproachtosemanticsegmentation.” classes (voc) challenge,” International journal of
in BMVC, 2008, pp. 1–10. [Online]. Avail- computervision,vol.88,no.2,pp.303–338,2010.
able: http://www.xrce.xerox.com/layout/set/print/ [EVGW+12] M. Everingham, L. Van Gool, C. K. I. Williams,
content/download/16654/118653/ﬁle/2008-023.pdf J. Winn, and A. Zisserman, “Visual object
[CRSS] A. Cohen, E. Rivlin, I. Shimshoni, and classeschallenge2012(voc2012),”2012.[Online].
E.Sabo,“Coloncryptsegmentationwebsite.”[On- Available:http://host.robots.ox.ac.uk:8080/pascal/
line].Available:http://mis.haifa.ac.il/~ishimshoni/ VOC/voc2012/index.html
SegmentCrypt/Download.htm
[Fel] P. F. Felzenszwalb, “Graph based im-
[CRSS14] ——, “Memory based active contour algorithm age segmentation.” [Online]. Available: http:
usingpixel-levelclassiﬁedimagesforcoloncrypt //cs.brown.edu/~pff/segment/
segmentation,” Computerized Medical Imaging
[FGMR10] P.F.Felzenszwalb,R.B.Girshick,D.McAllester,
and Graphics, Nov. 2014. [Online]. Available:
andD.Ramanan,“Objectdetectionwithdiscrimina-
http://mis.haifa.ac.il/~ishimshoni/SegmentCrypt/
tivelytrainedpart-basedmodels,”PatternAnalysis
Active%20contour%20based%20on%20pixel-
and Machine Intelligence, IEEE Transactions on,
level%20classiﬁed%20image%20for%20colon%
vol.32,no.9,pp.1627–1645,2010.
20crypts%20segmentation.pdf
[FH04] P. F. Felzenszwalb and D. P. Huttenlocher,
[CS10] J. Carreira and C. Sminchisescu, “Constrained
“Efﬁcient graph-based image segmentation,”
parametricmin-cutsforautomaticobjectsegmenta-
International Journal of Computer Vision,
tion,”inComputerVisionandPatternRecognition
vol. 59, no. 2, pp. 167–181, 2004. [Online].
(CVPR),2010IEEEConferenceon. IEEE,2010,
Available:http://link.springer.com/article/10.1023/
pp.3241–3248.
B:VISI.0000022288.19776.77
[CS11] ——,“Cpmc:Constrainedparametricmin-cutsfor
[FKG13] J. Fritsch, T. Kuehnl, and A. Geiger, “A
automaticobjectsegmentation,”Feb.2011.[Online].
new performance measure and evaluation
Available: http://www.maths.lth.se/matematiklth/
benchmark for road detection algorithms,” in
personal/sminchis/code/cpmc/
InternationalConferenceonIntelligentTransporta-
[CSI+09] M. E. Celebi, G. Schaefer, H. Iyatomi, W. V.
tion Systems (ITSC), 2013. [Online]. Available:
Stoecker,J.M.Malters,andJ.M.Grichnik,“An
http://www.cvlibs.net/datasets/kitti/eval_road.php
improvedobjectiveevaluationmeasureforborder
[GBVdW+10] J. M. Gonfaus, X. Boix, J. Van de Weijer, A. D.
detection in dermoscopy images,” Skin Research
Bagdanov,J.Serrat,andJ.Gonzalez,“Harmonypo-
andTechnology,vol.15,no.4,pp.444–450,2009.
tentialsforjointclassiﬁcationandsegmentation,”in
[Online].Available:http://arxiv.org/abs/1009.1020
ComputerVisionandPatternRecognition(CVPR),
[CSM09] L.P.Coelho,A.Shariff,andR.F.Murphy,“Nuclear
2010IEEEConferenceon. IEEE,2010,pp.3280–
segmentation in microscope cell images: a hand-
3287.
segmenteddatasetandcomparisonofalgorithms,”
in Biomedical Imaging: From Nano to Macro, [GRC+08] S. Gould, J. Rodgers, D. Cohen, G. Elidan, and
2009.ISBI’09.IEEEInternationalSymposiumon. D.Koller,“Multi-classsegmentationwithrelative
IEEE, 2009, pp. 518–521. [Online]. Available: locationprior,”InternationalJournalofComputer
http://murphylab.web.cmu.edu/data Vision,vol.80,no.3,pp.300–316,Apr.2008.
[CXGS12] M. D. Collins, J. Xu, L. Grady, and V. Singh, [GVSY13] S. Giannarou, M. Visentini-Scarzanella, and G.-
“Random walks based multi-image segmentation: Z.Yang,“Probabilistictrackingofafﬁne-invariant
Quasiconvexity results and gpu-based solutions,” anisotropicregions,”PatternAnalysisandMachine
in Computer Vision and Pattern Recognition Intelligence,IEEETransactionson,vol.35,no.1,
(CVPR), 2012 IEEE Conference on. IEEE, pp.130–143,2013.
2012, pp. 1656–1663. [Online]. Available: http: [Har75] J.A.Hartigan,Clusteringalgorithms. JohnWiley
//pages.cs.wisc.edu/~jiaxu/pub/rwcoseg.pdf &Sons,Inc.,1975.
[DHS15] J.Dai,K.He,andJ.Sun,“Instance-awareseman- [HDT02] C. Huang, L. Davis, and J. Townshend, “An
ticsegmentationviamulti-tasknetworkcascades,” assessment of support vector machines for land
arXivpreprintarXiv:1512.04412,2015. coverclassiﬁcation,”InternationalJournalofremote
[DT05] N. Dalal and B. Triggs, “Histograms of oriented sensing,vol.23,no.4,pp.725–749,2002.
gradients for human detection,” in Computer [HHR01] S.Hu,E.Hoffman,andJ.Reinhardt,“Automatic
Vision and Pattern Recognition, 2005. CVPR lung segmentation for accurate quantitation of
2005. IEEE Computer Society Conference on, volumetricx-rayctimages,”MedicalImaging,IEEE
13
Transactionson,vol.20,no.6,pp.490–498,Jun. invariant keypoints,” International Journal of
2001. ComputerVision,vol.60,no.2,pp.91–110,2004.
[HJBJ+96] A. Hoover, G. Jean-Baptiste, X. Jiang, P. J. [Online]. Available: http://dx.doi.org/10.1023/B%
Flynn, H. Bunke, D. B. Goldgof, K. Bowyer, 3AVISI.0000029664.99615.94
D. W. Eggert, A. Fitzgibbon, and R. B. [LRAL08] A. Levin, A. Rav-Acha, and D. Lischinski,
Fisher, “An experimental comparison of range “Spectral matting,” Pattern Analysis and
imagesegmentationalgorithms,”PatternAnalysis Machine Intelligence, IEEE Transactions on,
and Machine Intelligence, IEEE Transactions vol. 30, no. 10, pp. 1699–1712, 2008.
on, vol. 18, no. 7, pp. 673–689, Jul. 1996. [Online].Available:http://ieeexplore.ieee.org/xpls/
[Online].Available:http://ieeexplore.ieee.org/xpls/ abs_all.jsp?arnumber=4547428
abs_all.jsp?arnumber=506791 [LRKT09] L. Ladický, C. Russell, P. Kohli, and P. Torr,
[Ho95] T. K. Ho, “Random decision forests,” in “Associativehierarchicalcrfsforobjectclassimage
Document Analysis and Recognition, 1995., segmentation,”inComputerVision,2009IEEE12th
ProceedingsoftheThirdInternationalConference International Conference on, 2009, pp. 739–746.
on, vol. 1. IEEE, 1995, pp. 278–282. [Online].Available:http://ieeexplore.ieee.org/xpls/
[Online]. Available: http://ect.bell-labs.com/who/ abs_all.jsp?arnumber=5459248
tkh/publications/papers/odt.pdf [LSD14] J. Long, E. Shelhamer, and T. Darrell, “Fully
[Hus07] Hustvedt, “File:cctv lens ﬂare.jpg,” Wikipedia convolutionalnetworksforsemanticsegmentation,”
Commons, Nov. 2007. [Online]. Avail- arXiv preprint arXiv:1411.4038, 2014. [Online].
able: https://commons.wikimedia.org/wiki/File: Available:http://arxiv.org/abs/1411.4038
CCTV_Lens_ﬂare.jpg [MAFM08] M. Maire, P. Arbelaez, C. Fowlkes, and
[HZCP04] X. He, R. Zemel, and M. Carreira-Perpindn, J. Malik, “Using contours to detect and localize
“Multiscale conditional random ﬁelds for image junctions in natural images,” in Computer Vision
labeling,” in Computer Vision and Pattern and Pattern Recognition, 2008. CVPR 2008.
Recognition, 2004. CVPR 2004. Proceedings IEEE Conference on, June 2008, pp. 1–8.
of the 2004 IEEE Computer Society Conference [Online].Available:http://ieeexplore.ieee.org/xpls/
on, vol. 2, Jun. 2004, pp. II–695–II–702 Vol.2. abs_all.jsp?arnumber=4587420
[Online]. Available: http://ieeexplore.ieee.org/xpl/ [Man12] M. Manske, “File:randabschattung mikroskop
login.jsp?tp=&arnumber=1315232 kamera 6.jpg,” Wikipedia Com-
[JLD03] K.Jiang,Q.-M.Liao,andS.-Y.Dai,“Anovelwhite mons, Dec. 2012. [Online]. Avail-
bloodcellsegmentationschemeusingscale-space able: https://commons.wikimedia.org/wiki/File:
ﬁltering and watershed clustering,” in Machine Randabschattung_Mikroskop_Kamera_6.JPG
Learning and Cybernetics, 2003 International [MBLAGJ+07] S.Maldonado-Bascon,S.Lafuente-Arroyo,P.Gil-
Conferenceon,vol.5,Nov2003,pp.2820–2825 Jimenez, H. Gomez-Moreno, and F. Lopez-
Vol.5.[Online].Available:http://ieeexplore.ieee.org/ Ferreras, “Road-sign detection and recognition
xpl/login.jsp?tp=&arnumber=1260033 based on support vector machines,” Intelligent
[Kaf07] L.Kaffer,“File:greatmaleleopardinsouthafrika- Transportation Systems, IEEE Transactions on,
jd.jpg,”WikipediaCommons,Jul.2007.[Online]. vol. 8, no. 2, pp. 264–278, Jun. 2007.
Available:https://commons.wikimedia.org/wiki/File: [Online].Available:http://ieeexplore.ieee.org/xpls/
Great_male_Leopard_in_South_Afrika-JD.JPG abs_all.jsp?arnumber=4220659
[KKV+14] V.Kalesnykiene,J.-k.Kamarainen,R.Voutilainen, [MBVLG02] N.Moon,E.Bullitt,K.VanLeemput,andG.Gerig,
J. Pietilä, H. Kälviäinen, and H. Uusitalo, “Automaticbrainandtumorsegmentation,”inMed-
“Diaretdb1 diabetic retinopathy database and icalImageComputingandComputer-AssistedIn-
evaluation protocol,” 2014. [Online]. Available: tervention—MICCAI 2002. Springer, 2002, pp.
http://www2.it.lut.ﬁ/project/imageret/diaretdb1/ 372–379.
[KP92] J. M. Kasson and W. Plouffe, “An analysis of [MFTM01] D. Martin, C. Fowlkes, D. Tal, and J. Malik,
selectedcomputerinterchangecolorspaces,”ACM “A database of human segmented natural
TransactionsonGraphics(TOG),vol.11,no.4,pp. images and its application to evaluating
373–405,1992. segmentationalgorithmsandmeasuringecological
[KP06] Z. Kato and T.-C. Pong, “A markov random statistics,” in Computer Vision, 2001. ICCV
ﬁeld image segmentation model for color 2001. Proceedings. Eighth IEEE International
textured images,” Image and Vision Computing, Conferenceon,vol.2. IEEE,2001,pp.416–423.
vol. 24, no. 10, pp. 1103–1114, 2006. [Online]. [Online].Available:http://ieeexplore.ieee.org/xpls/
Available: http://www.sciencedirect.com/science/ abs_all.jsp?arnumber=937655
article/pii/S0262885606001223 [MHMK+14] L. Maier-Hein, S. Mersmann, D. Kondermann,
[KSH12] A. Krizhevsky, I. Sutskever, and G. E. Hinton, S. Bodenstedt, A. Sanchez, C. Stock, H. G.
“Imagenet classiﬁcation with deep convolutional Kenngott, M. Eisenmann, and S. Speidel, “Can
neuralnetworks,”inAdvancesinneuralinformation masses of non-experts train highly accurate
processingsystems,2012,pp.1097–1105. image classiﬁers?” in Medical Image Computing
[KWT88] M. Kass, A. Witkin, and D. Terzopoulos, andComputer-AssistedIntervention–MICCAI2014.
“Snakes: Active contour models,” International Springer,2014,pp.438–445.[Online].Available:
journal of computer vision, vol. 1, no. 4, pp. http://opencas.webarchiv.kit.edu/?q=node/26
321–331, Jan. 1988. [Online]. Available: http: [Min89] J.Mingers,“Anempiricalcomparisonofselection
//link.springer.com/article/10.1007/BF00133570 measures for decision-tree induction,” Machine
[LKJ15] F.-F. Li, A. Karpathy, and J. Johnson, Learning, vol. 3, no. 4, pp. 319–342, 1989.
“CS231n: Convolutional neural networks for [Online].Available:http://dx.doi.org/10.1023/A%
visual recognition,” 2015. [Online]. Available: 3A1022645801436
http://cs231n.stanford.edu/ [MSB12] G.Moser,S.B.Serpico,andJ.A.Benediktsson,
[Low04] D. Lowe, “Distinctive image features from scale- “Markovrandomﬁeldmodelsforsupervisedland
14
cover classiﬁcation from very high resolution tionstrategies,”Fundam.Inform.,vol.41,no.1-2,
multispectralremotesensingimages,”inAdvances pp.187–228,2000.
in Radar and Remote Sensing (TyWRRS), 2012 [RM07] J. Reynolds and K. Murphy, “Figure-ground
Tyrrhenian Workshop on. IEEE, 2012, pp. 235– segmentation using a hierarchical conditional
242.[Online].Available:http://ieeexplore.ieee.org/ random ﬁeld,” in Computer and Robot
xpl/login.jsp?tp=&arnumber=6381135 Vision, 2007. CRV ’07. Fourth Canadian
[MSC] “Object class recognition image database.” Conference on, May 2007, pp. 175–182.
[Online].Available:http://research.microsoft.com/ [Online].Available:http://ieeexplore.ieee.org/xpls/
vision/cambridge/recognition/ abs_all.jsp?arnumber=4228537
[MSR] “Image understanding - research data,” [RMBK06] C.Rother,T.Minka,A.Blake,andV.Kolmogorov,
Microsoft Research. [Online]. Avail- “Cosegmentation of image pairs by histogram
able:http://research.microsoft.com/en-us/projects/ matching - incorporating a global constraint
objectclassrecognition/ into mrfs,” in Computer Vision and Pattern
[Mur12] K. P. Murphy, Machine learning: a probabilistic Recognition, 2006 IEEE Computer Society
perspective. MITpress,2012. Conference on, vol. 1, June 2006, pp. 993–
[OKS78] Y.-i.Ohta,T.Kanade,andT.Sakai,“Ananalysis 1000.[Online].Available:http://ieeexplore.ieee.org/
systemforscenescontainingobjectswithsubstruc- xpls/abs_all.jsp?arnumber=1640859
tures,”inProceedingsoftheFourthInternational [SAN+04] J. Staal, M. D. Abràmoff, M. Niemeijer,
JointConferenceonPatternRecognitions,1978,pp. M.Viergever,B.VanGinnekenetal.,“Ridge-based
752–754. vesselsegmentationincolorimagesoftheretina,”
[PAA+87] S. M. Pizer, E. P. Amburn, J. D. Austin, Medical Imaging, IEEE Transactions on, vol. 23,
R. Cromartie, A. Geselowitz, T. Greer, B. ter no. 4, pp. 501–509, 2004. [Online]. Available:
HaarRomeny,J.B.Zimmerman,andK.Zuiderveld, http://www.isi.uu.nl/Research/Databases/DRIVE/
“Adaptivehistogramequalizationanditsvariations,” [SCZ08] F. Schroff, A. Criminisi, and A. Zisserman,
Computervision,graphics,andimageprocessing, “Object class segmentation using random
vol. 39, no. 3, pp. 355–368, 1987. [Online]. forests.” in BMVC, 2008, pp. 1–10. [On-
Available: http://www.sciencedirect.com/science/ line].Available:http://research.microsoft.com/pubs/
article/pii/S0734189X8780186X 72423/Criminisi_bmvc2008.pdf
[PC13] P. H. Pinheiro and R. Collobert, “Recurrent [SJC08] J. Shotton, M. Johnson, and R. Cipolla,
convolutional neural networks for scene parsing,” “Semantictextonforestsforimagecategorization
arXiv preprint arXiv:1306.2795, 2013. [Online]. and segmentation,” in Computer vision and
Available:http://arxiv.org/abs/1306.2795v1 pattern recognition, 2008. CVPR 2008. IEEE
[PH05] C. Pantofaru and M. Hebert, “A Conference on. IEEE, Jun. 2008, pp. 1–8.
comparison of image segmentation algorithms,” [Online].Available:http://ieeexplore.ieee.org/xpls/
Robotics Institute, p. 336, 2005. [Online]. abs_all.jsp?arnumber=4587503
Available: http://riweb-backend.ri.cmu.edu/ [SM11] C. Sutton and A. McCallum, “An introduction
pub_ﬁles/pub4/pantofaru_caroline_2005_1/ to conditional random ﬁelds,” Machine Learning,
pantofaru_caroline_2005_1.pdf vol. 4, no. 4, pp. 267–373, 2011. [Online].
[PS07] A. Protiere and G. Sapiro, “Interactive Available: http://homepages.inf.ed.ac.uk/csutton/
image segmentation via adaptive weighted publications/crftutv2.pdf
distances,” Image Processing, IEEE Transactions [Smi02] L. I. Smith, “A tutorial on principal components
on, vol. 16, no. 4, pp. 1046–1057, 2007. analysis,”CornellUniversity,USA,vol.51,p.52,
[Online].Available:http://ieeexplore.ieee.org/xpls/ 2002.
abs_all.jsp?arnumber=4130436 [Smi04] B.T.Smith,“Lagrangemultiplierstutorialinthe
[PTN09] N.Plath,M.Toussaint,andS.Nakajima,“Multi- contextofsupportvectormachines,”MemorialUni-
classimagesegmentationusingconditionalrandom versityofNewfoundlandSt.John’s,Newfoundland,
ﬁelds and global classiﬁcation,” in Proceedings Canada,Jun.2004.
of the 26th Annual International Conference on [SSA12] D.Schiebener,J.Schill,andT.Asfour,“Discovery,
MachineLearning. ACM,2009,pp.817–824. segmentation and reactive grasping of unknown
[PXP00] D. L. Pham, C. Xu, and J. L. Prince, “A objects.” in Humanoids, 2012, pp. 71–77. [On-
survey of current methods in medical image line]. Available: http://h2t.anthropomatik.kit.edu/
segmentation,” Annual Review of Biomedical pdf/Schiebener2012.pdf
Engineering, vol. 2, no. 1, pp. 315–337, 2000, [SUM+11] D. Schiebener, A. Ude, J. Morimotot,
pMID: 11701515. [Online]. Available: http:// T. Asfour, and R. Dillmann, “Segmentation
dx.doi.org/10.1146/annurev.bioeng.2.1.315 andlearningofunknownobjectsthroughphysical
[Qui86] J. R. Quinlan, “Induction of decision trees,” interaction,” in Humanoid Robots (Humanoids),
Machine learning, vol. 1, no. 1, pp. 81–106, 2011 11th IEEE-RAS International Conference
Aug. 1986. [Online]. Available: http://dx.doi.org/ on. IEEE, 2011, pp. 500–506. [Online].
10.1023/A%3A1022643204877 Available:http://ieeexplore.ieee.org/ielx5/6086637/
[Qui93] ——,C4.5:ProgramsforMachineLearning,P.Lan- 6100798/06100843.pdf
gley,Ed. MorganKaufmannPublishers,Inc.,1993. [SWRC06] J. Shotton, J. Winn, C. Rother, and A. Criminisi,
[RKB04] C.Rother,V.Kolmogorov,andA.Blake,“Grabcut: “Textonboost:Jointappearance,shapeandcontext
Interactive foreground extraction using iterated modeling for multi-class object recognition and
graph cuts,” ACM Transactions on Graphics segmentation,” in Computer Vision–ECCV 2006.
(TOG),vol.23,no.3,pp.309–314,2004.[Online]. Springer,2006,pp.1–15.[Online].Available:http:
Available:http://delivery.acm.org/10.1145/1020000/ //link.springer.com/chapter/10.1007/11744023_1
1015720/p309-rother.pdf [TNL14] J. Tighe, M. Niethammer, and S. Lazebnik,
[RM00] J. B. Roerdink and A. Meijster, “The watershed “Scene parsing with object instances and
transform:Deﬁnitions,algorithmsandparalleliza- occlusion ordering,” in Computer Vision and
15
Pattern Recognition (CVPR), 2014 IEEE GLOSSARY
Conference on. IEEE, 2014, pp. 3748–3755.
ACM active contour model. 6
[Online].Available:http://ieeexplore.ieee.org/xpls/
abs_all.jsp?arnumber=6909874
[UPH05] R. Unnikrishnan, C. Pantofaru, and M. Hebert, BOV bag-of-visual-words. 5
“A measure for objective evaluation of
image segmentation algorithms,” in Computer
CNN Convolution Neuronal Network. 5, 9
Vision and Pattern Recognition-Workshops, 2005.
CVPR Workshops. IEEE Computer Society CRF Conditional Random Field. 4, 8, 9, 11
Conference on. IEEE, 2005, pp. 34–34.
[Online].Available:http://repository.cmu.edu/cgi/ GPU graphics processing unit. 3
viewcontent.cgi?article=1365&context=robotics
[vdMPvdH09] L. J. van der Maaten, E. O. Postma, and H. J.
HOG histogram of oriented gradients. 5, 6, 8
vandenHerik,“Dimensionalityreduction:Acom-
parative review,” Journal of Machine Learning
Research,vol.10,no.1-41,pp.66–71,2009. ILSVRC ImageNet Large-Scale Visual Recognition
[VOC10] “Voc2010 preliminary results,” 2010. [Online].
Challenge. 9
Available:http://host.robots.ox.ac.uk/pascal/VOC/
voc2010/results/index.html
[WAH97] G.-Q.Wei,K.Arbter,andG.Hirzinger,“Automatic MAP Maximum A Posteriori. 8
tracking of laparoscopic instruments by color MR magnetic resonance. 2, 6
coding,” in CVRMed-MRCAS’97, ser. Lecture
MRF Markov Random Field. 4, 8
NotesinComputerScience,J.Troccaz,E.Grimson,
andR.Mösges,Eds. SpringerBerlinHeidelberg,
1997,vol.1205,pp.357–366.[Online].Available: PCA principal component analysis. 5
http://dx.doi.org/10.1007/BFb0029257
[YBCK10] Z. Yin, R. Bise, M. Chen, and T. Kanade, “Cell
RBF radial basis function. 8
segmentation in microscopy imagery using a
bag of local bayesian classiﬁers,” in Biomedical
Imaging: From Nano to Macro, 2010 IEEE SIFT scale-invariant feature transform. 5
InternationalSymposiumon,Apr.2010,pp.125– SVM Support Vector Machine. 4, 6–8
128.[Online].Available:http://ieeexplore.ieee.org/
xpls/abs_all.jsp?arnumber=5490399
[YHRF12] Y. Yang, S. Hallman, D. Ramanan, and
C. C. Fowlkes, “Layered object models for
image segmentation,” Pattern Analysis and
Machine Intelligence, IEEE Transactions on,
vol. 34, no. 9, pp. 1731–1743, Sep. 2012.
[Online].Available:http://ieeexplore.ieee.org/xpls/
abs_all.jsp?arnumber=6042883
[ZBS01] Y.Zhang,M.Brady,andS.Smith,“Segmentation
of brain MR images through a hidden Markov
random ﬁeld model and the expectation-
maximizationalgorithm,”MedicalImaging,IEEE
Transactions on, vol. 20, no. 1, pp. 45–57, 2001.
[Online].Available:http://ieeexplore.ieee.org/xpls/
abs_all.jsp?arnumber=906424
[ZGWX05] S.-C.Zhu,C.-E.Guo,Y.Wang,andZ.Xu,“What
are textons?” International Journal of Computer
Vision,vol.62,no.1-2,pp.121–143,2005.
[Zha12] Z.Zhang,“Microsoftkinectsensoranditseffect,”
MultiMedia, IEEE, vol. 19, no. 2, pp. 4–10, Feb.
2012.
[ZJRP+15] S. Zheng, S. Jayasumana, B. Romera-Paredes,
V. Vineet, Z. Su, D. Du, C. Huang, and
P. H. Torr, “Conditional random ﬁelds as
recurrent neural networks,” in Proceedings
of the IEEE International Conference on
Computer Vision, 2015, pp. 1529–1537. [Online].
Available: http://www.robots.ox.ac.uk/~szheng/
papers/CRFasRNN.pdf
16
APPENDIXA
TABLES
Number Number
Database ImageResolution(width×height) of of Channels Datasource
Images Classes
ColonCryptDB (302px−1116px)×(349px−875px) 389 2 3 [CRSS]
DIARETDB1 1500px×1500px 89 4 3 [KKV+14]
KITTIRoad (1226px−1242px)×(370px−376px) 289 2 3 [FKG13]
MSRCv1 (213px−320px)×(213px−320px) 240 9 3 [MSR]
MSRCv2 (213px−320px)×(162px−320px) 591 23 3 [MSR]
Open-CASEndoscopicDatasets 640px×480px 120 2 3 [MHMK+14]
PASCALVOC2012 (142px−500px)×( 71px−500px) 2913 20 3 [EVGW+12]
Warwick-QU (567px−775px)×(430px−522px) 165 5 3 [CSM09]
Table I: An overview over publicly available image databases with a semantic segmentation ground trouth.
